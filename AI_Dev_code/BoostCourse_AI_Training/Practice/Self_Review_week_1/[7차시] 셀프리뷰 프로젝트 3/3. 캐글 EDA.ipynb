{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# [셀프리뷰 프로젝트] 3. 캐글 EDA\n","\n","✔︎ 이번 프로젝트의 진행방식은 다음과 같습니다 :\n","- '셀프리뷰 프로젝트'는 코치의 리뷰를 거치지 않는 프로젝트입니다.\n","- 첨부된 파일에 안내된 절차에 따라 최소 5~10줄 이내의 간단한 코드를 작성함으로 스스로의 실력을 체크할 수 있습니다.\n","- 프로젝트 수행 결과 화면을 캡처 및 제출시, 담당코치가 훈련생 분의 학습현황을 파악하고 채점을 진행합니다.\n","\n","✔︎ 프로젝트 수행에 어려움을 겪고 있다면?\n","- 만약 프로젝트 수행에 어려움을 겪고 있거나 제출을 끝냈다면, 코치 1:1 문의를 통해 예시 정답을 요청해 보세요.\n","- 웍스와 자유게시판을 통해 다른 훈련생들과 문제점을 공유하고 해결방안을 도모하는 것도 좋은 방법입니다."],"metadata":{"id":"hYlz1Il-XOn8"}},{"cell_type":"markdown","source":["## 1. EDA (1) : 라벨 제거 및 결측치 확인"],"metadata":{"id":"mYUxezAl9EVx"}},{"cell_type":"code","source":["# 앞선 프로젝트에서 저장한 train data 에서 불필요한 값을 제거합니다.\n","# isna() 함수로 결측치를 확인하고, describe() 함수를 활용해 기본적인 통계량를 확인합니다.\n","# missingno 라이브러리를 통해 결측치를 시각화하고, 변수들의 분포를 확인합니다."],"metadata":{"id":"BJ63RCQm9L_o"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### [TODO] 1_ 학습 데이터에서 라벨 제거하기\n","\n","학습데이터인 `data`는 테스트 데이터인 `sub`와 달리 우리가 예측해야 할 `price`란  컬럼을 하나 더 가지고 있습니다. 이제부터 학습데이터(`data`)의 `price`를 `y`라는 정답을 담는 변수로 옮기고 `data`에서는 `price`컬럼을 제거 하려고 합니다.\n","\n","이를 직접 구현해 보세요.\n","\n","```\n","[힌트]\n","- 파이썬의 del 명령어를 사용하여 특정컬럼을 지울 수 있습니다\n","- pandas.DataFrame.drop도 활용할 수 있습니다\n","\n","```"],"metadata":{"id":"Hg8ZIt1t9TPh"}},{"cell_type":"code","source":["# data의 price를 y로 옮기기\n","y = data['price']\n","\n","#######################################\n","#### 3-1. 알맞은 코드를 직접 작성해보세요! ####\n","#######################################"],"metadata":{"id":"HrI9LD7Q9biU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["코드를 잘 작성하셨다면 아래의 `data.colums`를 출력하였을 때 Index에 'price'가 없어야 합니다."],"metadata":{"id":"MBR4prCM9xEi"}},{"cell_type":"code","source":["print(data.columns)"],"metadata":{"id":"_VsE_1q_9yfw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["모델을 학습시키기 전에 학습데이터와 테스트 데이터를 합쳐서 전체 데이터가 어떤 특성을 보이고 있는지 살펴보려고 합니다. 특성을 살펴보고 난 후엔 다시 분리하여 학습을 진행할것 입니다.\n","이를위해 학습데이터(`data`)의 개수를 저장하여 합쳐진 데이터에서 분리할 것 입니다.\n","아래의 코드는 이를 실행합니다."],"metadata":{"id":"TzE-ZOuI9z_f"}},{"cell_type":"code","source":["train_len = len(data) # 학습데이터의 수\n","data = pd.concat((data, sub), axis=0) # 학습데이터와 테스트 데이터 합치기\n","\n","print(len(data)) # 합쳐진 데이터의 수\n","data.head() # 데이터 확인"],"metadata":{"id":"4cyFlnij92XQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["`data`를 확인해보면 `data`와 `sub`가 잘 합쳐진 것을 확인하실 수 있을 겁니다.\n","이제부터 데이터에 결측치가 있는지 확인해보겠습니다.\n","\n","그리고 `info()`함수로 데이터 타입 및 null 체크를 해보겠습니다."],"metadata":{"id":"KB9LpCbb95nN"}},{"cell_type":"code","source":["data.info()"],"metadata":{"id":"syKyhnpa-B5k"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### [TODO] 2_ 결측치 데이터의 비율 계산하기\n","\n","위 `info`함수를 이용하면 각 컬럼에 null 데이터가 몇개 존재하는지 확인할 수있습니다. 아래에서는 유사한 방법으로 `isna()`로 결측치 데이터를 확인하고 그 수를 `sum()`함수로 세어보겠습니다.\n","\n","- 참고 : [`isna()`](https://pandas.pydata.org/docs/reference/api/pandas.isna.html)와 [`sum()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sum.html)"],"metadata":{"id":"Ma_1mUKo-FnO"}},{"cell_type":"code","source":["#######################################\n","#### 3-2. 빈칸(...)에 알맞은 코드를 직접 작성해보세요! ####\n","#######################################\n","\n","missing = ...\n","print(missing)"],"metadata":{"id":"dlbd-ZqG-JKj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["출력하였을 때 다음과 같은 결과가 나오면 됩니다.\n","\n","> id               0 <br>\n","date             0 <br>\n","price            0 <br>\n","bedrooms         0 <br>\n","bathrooms        0 <br>\n","sqft_living      0 <br>\n","sqft_lot         0 <br>\n","floors           0 <br>\n","waterfront       0 <br>\n","view             0 <br>\n","condition        0 <br>\n","grade            0 <br>\n","sqft_above       0 <br>\n","sqft_basement    0 <br>\n","yr_built         0 <br>\n","yr_renovated     0 <br>\n","zipcode          0 <br>\n","lat              0 <br>\n","long             0 <br>\n","sqft_living15    0 <br>\n","sqft_lot15       0 <br>\n","dtype: int64 <br>\n","\n"],"metadata":{"id":"FNMSDQUB-SjR"}},{"cell_type":"markdown","source":["이제 missing을 전체 데이터의 수로 나눈다면 컬럼별 결측치 데이터의 비율을 알 수 있게 됩니다."],"metadata":{"id":"ijqKutql-WdO"}},{"cell_type":"code","source":["missing/data.shape[0]"],"metadata":{"id":"ocqlW5E--YMq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["`describe()`함수를 이용하면 수치형 데이터의 기본적인 통계량을 확인해볼 수 있습니다. 이를 활용해 봅니다."],"metadata":{"id":"XlwHBDOa-Yui"}},{"cell_type":"code","source":["data.describe()"],"metadata":{"id":"27K968Ow-bWp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### [TODO] 3_ `missingno` 라이브러리로 결측치 데이터 시각화 하기\n","\n","결측치 데이터를 시각화하면 결측치를 어떻게 처리할지 통찰을 얻을 수도 있습니다. 이를 위해서 `missingno` 라이브러리의 [`matrix`](https://github.com/ResidentMario/missingno#matrix) 함수를 이용할 수 있습니다.\n","\n","`data`를 `missingno` 라이브러리를 활용하여 시각화해보세요.\n","\n","msno를 활용하여 시각화하면, 위에서 계산한 것처럼 결손치 데이터가 없기 때문에 까맣게 나왔을 겁니다. 시각화를 통해 결손치를 발생 시키는 원인이 어떤 컬럼으로부터 기인했는지 유추해 볼 수 있고 적절한 결손치 처리 방법에 대한 아이디어를 얻을 수 있습니다."],"metadata":{"id":"z17Jm2tDXioR"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"RuEp2d7tXCoy"},"outputs":[],"source":["import missingno as msno # 라이브러리 임포트\n","\n","# data에 결손치를 missingno 라이브러리를 이용하여 시각화 해보세요.\n","\n","#######################################\n","#### 3-3. 알맞은 코드를 직접 작성해보세요! ####\n","#######################################"]},{"cell_type":"markdown","source":["### 4_ 불필요한 변수 정리하기\n","\n","**id컬럼 제거하기**\n","\n","우리의 목표는 `price`를 예측하는 것이기 때문에 필요없는 `id`를 제거하겠습니다. 그전에 제출할때 대비하여 `sub_id` 변수에 `id` 컬럼을 저장해 두고 지우겠습니다."],"metadata":{"id":"28LelQJSXzJC"}},{"cell_type":"code","source":["sub_id = data['id'][train_len:]\n","del data['id']\n","\n","print(data.columns)"],"metadata":{"id":"iJnGK29ZX0_S"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**date 컬럼 자르기**\n","\n","date 컬럼의 값을 보면 다음과 같은 형식으로 되어있는 것을 확인할 수 있습니다.\n","- 예시 : `20141013T000000`\n","\n","우리는 연/월 데이터만 사용하기 위해 `201410` 까지 자르기 변환을 수행할 것 입니다. 이를 위해서 아래의 코드를 실행합니다."],"metadata":{"id":"iwXTOIr7X3Ur"}},{"cell_type":"code","source":["data['date'] = data['date'].apply(lambda x : str(x[:6]))\n","data.head()"],"metadata":{"id":"s-9gi6XQX4u3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2. EDA(2) : 로그 변환"],"metadata":{"id":"1hVbtrCxAygC"}},{"cell_type":"code","source":["# 분포가 치우쳐진 변수들에 대해 로그 변환을 진행하고, 데이터를 정규분포에 가깝게 만듭니다.\n","# 변환한 데이터를 다시 train data 와 test data 로 나누어 저장합니다."],"metadata":{"id":"Nt2yLxGcBSd9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### [TODO] 5_ 각 변수들의 분포 확인 및 변환하기\n","\n","전체 데이터들의 분포를 확인합니다.\n","특히 너무 치우친 분포를 가지는 컬럼의 경우 모델이 결과를 예측하는 데에 좋지 않은 영향을 미치므로 다듬는 작업을 합니다.\n","\n","아래 시각화 코드는 id 컬럼과 date컬럼을 제외한 18개 컬럼에 대해 한 번에 모든 그래프의 분포를 그려주는 코드입니다.\n","9행 2열의 subplot에 그래프를 그리기 위해 2중 for문을 사용하고 있군요.\n","\n","그래프의 종류는 [sns.kdeplot](https://seaborn.pydata.org/generated/seaborn.kdeplot.html)을 사용합니다.\n","kdeplot은 이산(discrete) 데이터의 경우에도 부드러운 곡선으로 전체 분포를 확인할 수 있도록 하는 시각화 함수입니다.\n"],"metadata":{"id":"qmyfv-3LX5xt"}},{"cell_type":"code","source":["fig, ax = plt.subplots(9, 2, figsize=(12, 50))   # 가로스크롤 때문에 그래프 확인이 불편하다면 figsize의 x값을 조절해 보세요.\n","\n","# date 변수(count==0인 경우)는 제외하고 분포를 확인\n","count = 1\n","columns = data.columns\n","for row in range(9):\n","    for col in range(2):\n","        sns.kdeplot(data=data[columns[count]], ax=ax[row][col])\n","        ax[row][col].set_title(columns[count], fontsize=15)\n","        count += 1\n","        if count == 19 :\n","            break"],"metadata":{"id":"1by-qhV6X7GN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["위 그래프 중에서는 `bedrooms`, `sqft_living`, `sqft_lot`, `sqft_above`, `sqft_basement`, `sqft_living15`, `sqft_lot15` 변수가 한쪽으로 치우친 경향을 보이는군요.\n","\n","이렇게 한 쪽으로 치우친 분포의 경우에는 로그 변환(log-scaling)을 통해 데이터 분포를 정규분포에 가깝게 만들 수 있습니다.\n","\n","\n"],"metadata":{"id":"Y7phWfeqX9Qw"}},{"cell_type":"markdown","source":["**로그변환 수행하기 (log-scaling)**\n","\n","아래와 같이 치우친 컬럼들을 `skew_columns` 리스트 안에 담고, 모두 [`np.log1p()`](https://numpy.org/doc/stable/reference/generated/numpy.log1p.html)를 활용해서 로그 변환을 해주도록 하겠습니다. `numpy.log1p()`함수는 입력배열의 각 요소에 대해 자연로그 log(1+x)을 반환해 주는 함수 입니다."],"metadata":{"id":"8SytQQ_6X9vA"}},{"cell_type":"code","source":["# 치우친 분포의 컬럼을 저장해 두기\n","skew_columns = ['bedrooms', 'sqft_living', 'sqft_lot', 'sqft_above', 'sqft_basement', 'sqft_lot15', 'sqft_living15']\n","\n","#######################################\n","#### 3-4. 알맞은 코드를 직접 작성해보세요! ####\n","#######################################\n","\n","for c in skew_columns:\n","    data[c] = ...\n"],"metadata":{"id":"m9xRk6VnYBjR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["log(1+x)변환을 완료하셨나요? 취우쳐 있던 `skew_colums`만을 다시 `sns.kdeplot`으로 출력해보도록 하겠습니다. 이전 출력보다 치우침이 줄어드는것이 확인 되었다면 코드블록 3-4 를 잘 구현하신것 입니다.\n"],"metadata":{"id":"H4lTAJCxYI1E"}},{"cell_type":"code","source":["fig, ax = plt.subplots(4, 2, figsize=(12, 24))\n","\n","count = 0\n","for row in range(4):\n","    for col in range(2):\n","        if count == 7:\n","            break\n","        sns.kdeplot(data=data[skew_columns[count]], ax=ax[row][col])\n","        ax[row][col].set_title(skew_columns[count], fontsize=15)\n","        count += 1"],"metadata":{"id":"y-ylK2uNYJoy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["그렇다면 왜 로그 변환은 분포의 치우침을 줄어들게 만드는 걸까요?\n","이는 로그 함수의 형태를 보면 알 수 있습니다. 아래의 일반적인 로그 함수를 살펴봅시다."],"metadata":{"id":"e_PvX2ofYLPT"}},{"cell_type":"code","source":["xx = np.linspace(0, 10, 500)\n","yy = np.log(xx)\n","\n","plt.hlines(0, 0, 10)\n","plt.vlines(0, -5, 5)\n","plt.plot(xx, yy, c='r')\n","plt.show()"],"metadata":{"id":"TWBrOOXLYMJI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["위와 같은 로그 함수의 특징은 다음과 같습니다.\n","\n","- 0<x<1 범위에서는 기울기가 매우 가파릅니다. 즉, x의 구간은 (0,1)로 매우 짧은 반면, y의 구간은 (−∞,0)으로 매우 큽니다.\n","- 따라서 0에 가깝게 모여있는 값들이 x로 입력되면, 그 함수값인 y 값들은 매우 큰 범위로 벌어지게 됩니다. 즉, 로그 함수는 0에 가까운 값들이 조밀하게 모여있는 입력값을, 넓은 범위로 펼칠 수 있는 특징을 가집니다.\n","- 반면, x값이 점점 커짐에 따라 로그 함수의 기울기는 급격히 작아집니다. 이는 곧 큰 x값들에 대해서는 y값이 크게 차이나지 않게 된다는 뜻이고, 따라서 넓은 범위를 가지는 x를 비교적 작은 y값의 구간 내에 모이게 하는 특징을 가집니다."],"metadata":{"id":"5T6USSUEYNIb"}},{"cell_type":"markdown","source":["위와 같은 특성 때문에 한 쪽으로 몰려있는 분포에 로그 변환을 취하게 되면 넓게 퍼질 수 있는 것이죠.\n","\n","왜 한쪽으로 치우친 분포를 로그 변환을 취하게 되면 정규분포 모양으로 고르게 분포하게 될 수 있는지 이해가 되시나요? 그렇다면 우리가 맞추어야 할 타겟인 집의 가격, 즉 `data[price]`의 분포를 로그 변환했을 때 결과를 유추해봅시다. 원래 price의 분포는 다음과 같습니다."],"metadata":{"id":"qrrNYxeGYXQx"}},{"cell_type":"code","source":["sns.kdeplot(y) # y는 코드블록 3-2 에서 price를 저장하고 있음.\n","plt.show()"],"metadata":{"id":"FKO0GGZHYPs1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["직접 확인해봅시다!"],"metadata":{"id":"YEBvRkl3YTqV"}},{"cell_type":"code","source":["y_log_transformation = np.log1p(y) # 코드블록 3-4 의 힌트가 되겠네요 ^^\n","\n","sns.kdeplot(y_log_transformation)\n","plt.show()"],"metadata":{"id":"Y7TRhGgDYbHd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["확실히 아름다운 정규분포의 모양으로 가까워진 것으로 보입니다!"],"metadata":{"id":"0uLHmTX2YcFP"}},{"cell_type":"markdown","source":["### 6_ 다시 학습데이터와 테스트 데이터 분리하기\n","\n","여기까지 로그 변환이 필요한 데이터에 대해 처리를 마무리하였으니, 아래와 같이 전체 데이터를 다시 나누어 줍니다.\n","\n","위에서 저장해두었던 `train_len`을 인덱스로 활용해서 `:train_len`까지는 학습 데이터, 즉 `x`에 저장하고, `train_len:` 부터는 실제로 추론을 해야 하는 테스트 데이터, 즉 `sub` 변수에 저장합니다."],"metadata":{"id":"QwPEYBKgYeMw"}},{"cell_type":"code","source":["sub = data.iloc[train_len:, :]\n","x = data.iloc[:train_len, :]\n","\n","print(x.shape)\n","print(sub.shape)"],"metadata":{"id":"rpKvGOeDYlaB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["여러분, 이제 데이터 준비를 마쳤습니다. 다음 시간에는 실제 모델을 적용하여 price를 예측해보고 그 결과를 캐글 대회에 제출해보도록 하겠습니다."],"metadata":{"id":"p0PHkk-DYmj4"}},{"cell_type":"markdown","source":["## 3. 셀프리뷰 진행하기\n","\n","- 수행한 프로젝트 내용을 확인하고, 셀프리뷰를 진행합니다.\n","- 내가 작성한 코드에 오류는 없는지 또는 더 나은 방법은 없는지 고민해 봅니다.\n","- 리뷰를 완료했다면, 실행 결과 화면을 캡쳐 및 제출하여 수행여부를 증빙합니다. (파일첨부 NO! 본문에 이미지 삽입 YES!)\n","- 이번 차시에 궁금한 점이 있다면, 제출시 본문에 내용을 함께 작성하여 제출할 수 있습니다."],"metadata":{"id":"LbCeT9mXA2Nw"}},{"cell_type":"markdown","source":["ALL RIGHTS RESERVED. (C)NAVER Connect Foundation."],"metadata":{"id":"FydzbAT6YnbW"}}]}