{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d05b706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentiWord_info.json 감성사전을 성공적으로 불러왔습니다. (총 14852개 단어)\n",
      "분석할 CSV 파일들을 성공적으로 불러왔습니다.\n",
      "==================================================\n",
      "카테고리별 감성 점수 계산 시작...\n",
      "'cheongju' 데이터프레임 점수 계산 완료.\n",
      "'other' 데이터프레임 점수 계산 완료.\n",
      "==================================================\n",
      "최종 분석 결과를 새로운 CSV 파일로 저장합니다...\n",
      "청주 데이터 최종 결과가 './crawled_data/merged_cheongju_final.csv' 파일에 저장되었습니다.\n",
      "다른 지역 데이터 최종 결과가 './crawled_data/merged_other_final.csv' 파일에 저장되었습니다.\n",
      "==================================================\n",
      "\n",
      "--- 청주 데이터프레임 최종 분석 결과 (상위 5개) ---\n",
      "                                               음식_문장     음식_점수  \\\n",
      "0  ['메뉴저희는고추장불고기 더덕구이정식으로 2인분주문했어요', '점심특선 고추장불고기...  0.928571   \n",
      "1  ['날씨가 덥다 보니 사람들이 많이 먹는 음식 중에 하나가 냉면일 거 같아요', '...  1.428571   \n",
      "2  ['지도 컨트롤러 범례부동산거리읍,면,동시,군,구시,도국가짜글이전문점 진주식당충청북...  2.409091   \n",
      "3  ['청주 가경동 일식 코스 요리가족 모임하기 좋은 룸식당 어도횟집글, 사진 네정 안...  2.250000   \n",
      "4  ['원래 고깃집은 워낙 자주 가는 편인데요, 친구가 요즘 청주에서 먹은 고기 중 최...  2.933333   \n",
      "\n",
      "                                              분위기_문장  분위기_점수  \\\n",
      "0  ['안쪽으로도 자리가 많더라구요', '저희가 방문했을때식당내부는 손님으로가득해서 늦...    0.00   \n",
      "1  ['너무 달게 된 무는 제가 안 먹는 편이어서새콤한 맛하고 시원한 맛이 좋은데 너무...    6.00   \n",
      "2  ['3. 매장 둘러보기 여름에도 시원하고 쾌적한 공간 테이블 많았고, 매장 전반적으...    2.50   \n",
      "3  ['청주 가경동 일식 코스 요리가족 모임하기 좋은 룸식당 어도횟집글, 사진 네정 안...    3.00   \n",
      "4  ['생갈비도 마블링이 예쁘게 들어가 있어서 구울 때부터 고소한 향이 올라오는데, 입...    3.25   \n",
      "\n",
      "                                               가격_문장     가격_점수  \\\n",
      "0  ['요즘 물가가 많이 올랐는대만원도 안되는 가격으로저런 구성이면가성비가 좋다고 생각...  2.000000   \n",
      "1  ['옆으로는 얼음이 동동 떠 있고여기는 적당하게 얼음이 들어가 있네요', '적당하게...  2.500000   \n",
      "2  ['메뉴 주문 후 이벤트 참여한다고 말씀해 주시면 바로 계산하면서 영수증 갖다주시니...  1.000000   \n",
      "3  ['청주 가경동 일식 코스 요리가족 모임하기 좋은 룸식당 어도횟집글, 사진 네정 안...  2.083333   \n",
      "4  ['저희가 주문한 메뉴는 둘이서세트 에 밀면 하나 추가해서 총 56,000원어치였어...  2.666667   \n",
      "\n",
      "                                              서비스_문장    서비스_점수  \n",
      "0  ['청주 가경동에 위치한더덕한상 입니다', '위치정보50 . .더보기 지도 데이터 ...  0.250000  \n",
      "1  ['저도 들어가서 물 냉면으로 하나 주문을 했어요', '곱빼기 있는 이유가 많이 드...  3.000000  \n",
      "2  ['2. 메뉴 2인 이상 주문시 부침개 서비스 대추나무집과 비슷하게 짜글이가 두종류...  1.714286  \n",
      "3  ['기념일인 만큼 분위기 좋고,조용하게 식사할 수 있는 룸식당프라이빗한 코스요리 맛...  2.333333  \n",
      "4  ['저희가 주문한 메뉴는 둘이서세트 에 밀면 하나 추가해서 총 56,000원어치였어...  3.500000  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from konlpy.tag import Okt\n",
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "# --- 1. SentiWord_info.json 파일 \"한 번만\" 불러와 딕셔너리로 만들기 ---\n",
    "senti_dic_path = './KNU/KnuSentiLex/data/SentiWord_info.json'  # 사용자가 업로드한 파일 경로\n",
    "try:\n",
    "    with open(senti_dic_path, 'r', encoding='utf-8') as f:\n",
    "        senti_data = json.load(f)\n",
    "    # 파일을 성공적으로 읽었으므로, {단어: 점수} 형태의 딕셔너리로 변환합니다.\n",
    "    senti_dict = {item['word']: int(item['polarity']) for item in senti_data}\n",
    "    print(f\"SentiWord_info.json 감성사전을 성공적으로 불러왔습니다. (총 {len(senti_dict)}개 단어)\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"오류: '{senti_dic_path}' 파일을 찾을 수 없습니다. 파일 경로를 확인해주세요.\")\n",
    "    senti_dict = {}\n",
    "except json.JSONDecodeError:\n",
    "    print(f\"오류: '{senti_dic_path}' 파일이 올바른 JSON 형식이 아닙니다.\")\n",
    "    senti_dict = {}\n",
    "\n",
    "\n",
    "# --- 2. 분석할 데이터 불러오기 ---\n",
    "# 이전 단계에서 문장 추출이 완료된 CSV 파일 경로\n",
    "cheongju_analyzed_path = \"./crawled_data/merged_cheongju_analyzed_fnai.csv\"\n",
    "other_analyzed_path = \"./crawled_data/merged_other_analyzed_fnai.csv\"\n",
    "\n",
    "try:\n",
    "    cheongju_df = pd.read_csv(cheongju_analyzed_path, encoding='utf-8-sig')\n",
    "    other_df = pd.read_csv(other_analyzed_path, encoding='utf-8-sig')\n",
    "    print(\"분석할 CSV 파일들을 성공적으로 불러왔습니다.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"오류: 분석할 CSV 파일을 찾을 수 없습니다. 이전 단계가 정상적으로 완료되었는지 확인해주세요.\")\n",
    "    cheongju_df = pd.DataFrame()\n",
    "    other_df = pd.DataFrame()\n",
    "\n",
    "okt = Okt()\n",
    "print(\"=\"*50)\n",
    "\n",
    "\n",
    "# --- 3. 카테고리별 점수 계산 함수 정의 ---\n",
    "def calculate_category_scores_efficiently(row):\n",
    "    categories = ['음식', '분위기', '가격', '서비스']\n",
    "    final_scores = {}\n",
    "\n",
    "    for category in categories:\n",
    "        sentence_column = f'{category}_문장'\n",
    "        try:\n",
    "            sentences = ast.literal_eval(row[sentence_column]) if isinstance(row[sentence_column], str) and row[sentence_column].startswith('[') else []\n",
    "        except:\n",
    "            sentences = []\n",
    "\n",
    "        if not sentences:\n",
    "            final_scores[f'{category}_점수'] = 0\n",
    "            continue\n",
    "\n",
    "        category_total_score = 0\n",
    "        sentence_count_with_sentiment = 0\n",
    "        \n",
    "        for sentence in sentences:\n",
    "            try:\n",
    "                morphs = okt.pos(sentence, stem=True)\n",
    "                words = [word for word, pos in morphs if pos in ['Noun', 'Verb', 'Adjective']]\n",
    "            except:\n",
    "                words = []\n",
    "            \n",
    "            sentence_score = 0\n",
    "            sentiment_word_count = 0\n",
    "            for word in words:\n",
    "                # 미리 만들어 둔 senti_dict에서 직접 점수를 조회합니다 (파일을 다시 읽지 않아 매우 빠름)\n",
    "                if word in senti_dict:\n",
    "                    sentence_score += senti_dict[word]\n",
    "                    sentiment_word_count += 1\n",
    "            \n",
    "            if sentiment_word_count > 0:\n",
    "                category_total_score += sentence_score\n",
    "                sentence_count_with_sentiment += 1\n",
    "\n",
    "        if sentence_count_with_sentiment > 0:\n",
    "            final_scores[f'{category}_점수'] = category_total_score / sentence_count_with_sentiment\n",
    "        else:\n",
    "            final_scores[f'{category}_점수'] = 0 # 감성 단어가 없는 경우 0점(중립)으로 처리\n",
    "\n",
    "    return pd.Series(final_scores)\n",
    "\n",
    "# --- 4. 데이터프레임에 함수 적용 ---\n",
    "print(\"카테고리별 감성 점수 계산 시작...\")\n",
    "\n",
    "if not cheongju_df.empty and senti_dict:\n",
    "    cheongju_scores = cheongju_df.apply(calculate_category_scores_efficiently, axis=1)\n",
    "    cheongju_final = pd.concat([cheongju_df, cheongju_scores], axis=1)\n",
    "    print(\"'cheongju' 데이터프레임 점수 계산 완료.\")\n",
    "\n",
    "if not other_df.empty and senti_dict:\n",
    "    other_scores = other_df.apply(calculate_category_scores_efficiently, axis=1)\n",
    "    other_final = pd.concat([other_df, other_scores], axis=1)\n",
    "    print(\"'other' 데이터프레임 점수 계산 완료.\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# --- 5. 최종 결과 확인 및 저장 ---\n",
    "output_cheongju_path_final = \"./crawled_data/merged_cheongju_fnai_final.csv\"\n",
    "output_other_path_final = \"./crawled_data/merged_other_fnai_final.csv\"\n",
    "\n",
    "print(\"최종 분석 결과를 새로운 CSV 파일로 저장합니다...\")\n",
    "\n",
    "if 'cheongju_final' in locals():\n",
    "    cheongju_final.to_csv(output_cheongju_path_final, encoding='utf-8-sig', index=False)\n",
    "    print(f\"청주 데이터 최종 결과가 '{output_cheongju_path_final}' 파일에 저장되었습니다.\")\n",
    "\n",
    "if 'other_final' in locals():\n",
    "    other_final.to_csv(output_other_path_final, encoding='utf-8-sig', index=False)\n",
    "    print(f\"다른 지역 데이터 최종 결과가 '{output_other_path_final}' 파일에 저장되었습니다.\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# --- 최종 결과 데이터프레임 일부 출력 ---\n",
    "print(\"\\n--- 청주 데이터프레임 최종 분석 결과 (상위 5개) ---\")\n",
    "if 'cheongju_final' in locals():\n",
    "    display_cols = ['음식_문장', '음식_점수', '분위기_문장', '분위기_점수', '가격_문장', '가격_점수', '서비스_문장', '서비스_점수']\n",
    "    print(cheongju_final[display_cols].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d081845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- 청주 최대 점수 출력 -----\n",
      "청주 데이터 최대 점수:\n",
      "음식_점수     19.0\n",
      "분위기_점수    24.0\n",
      "가격_점수     25.5\n",
      "서비스_점수    24.0\n",
      "dtype: float64\n",
      "\n",
      "--- 다른 지역 최대 점수 출력 ---\n",
      "다른 지역 데이터 최대 점수:\n",
      "음식_점수     22.0\n",
      "분위기_점수    29.0\n",
      "가격_점수     21.0\n",
      "서비스_점수    21.0\n",
      "dtype: float64\n",
      "==================================================\n",
      "----- 청주 최소 점수 출력 -----\n",
      "청주 데이터 최소 점수:\n",
      "음식_점수    -2.0\n",
      "분위기_점수   -3.0\n",
      "가격_점수    -4.0\n",
      "서비스_점수   -4.0\n",
      "dtype: float64\n",
      "\n",
      "--- 다른 지역 최소 점수 출력 ---\n",
      "다른 지역 데이터 최소 점수:\n",
      "음식_점수    -2.0\n",
      "분위기_점수   -7.0\n",
      "가격_점수    -6.0\n",
      "서비스_점수   -4.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 최대 점수 출력\n",
    "print(\"----- 청주 최대 점수 출력 -----\")\n",
    "if 'cheongju_final' in locals():\n",
    "    max_scores = cheongju_final[['음식_점수', '분위기_점수', '가격_점수', '서비스_점수']].max()\n",
    "    print(\"청주 데이터 최대 점수:\")\n",
    "    print(max_scores)\n",
    "\n",
    "print(\"\\n--- 다른 지역 최대 점수 출력 ---\")\n",
    "if 'other_final' in locals():\n",
    "    max_other_scores = other_final[['음식_점수', '분위기_점수', '가격_점수', '서비스_점수']].max()\n",
    "    print(\"다른 지역 데이터 최대 점수:\")\n",
    "    print(max_other_scores)\n",
    "\n",
    "print(\"=\"*50)\n",
    "\n",
    "# 최소 점수 출력\n",
    "print(\"----- 청주 최소 점수 출력 -----\")\n",
    "if 'cheongju_final' in locals():\n",
    "    min_scores = cheongju_final[['음식_점수', '분위기_점수', '가격_점수', '서비스_점수']].min()\n",
    "    print(\"청주 데이터 최소 점수:\")\n",
    "    print(min_scores)\n",
    "print(\"\\n--- 다른 지역 최소 점수 출력 ---\")\n",
    "if 'other_final' in locals():\n",
    "    min_other_scores = other_final[['음식_점수', '분위기_점수', '가격_점수', '서비스_점수']].min()\n",
    "    print(\"다른 지역 데이터 최소 점수:\")\n",
    "    print(min_other_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e655263e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- 청주 최소 점수 문장 출력 -----\n",
      "청주 데이터 최소 점수 문장:\n",
      "음식_문장     ['사장님 120분 기다리면 고기 10인분 콜?', '저거 단품으로 팔아도 사먹을텐...\n",
      "분위기_문장    ['저희는..사람없는 시간을 골라서 가니깐웨이팅이..읍어요 평일 16 00 24 0...\n",
      "가격_문장     ['저희는..사람없는 시간을 골라서 가니깐웨이팅이..읍어요 평일 16 00 24 0...\n",
      "서비스_문장    ['고기가 구워져서 나오니깐해물전골 느린느낌느린게 아닌데 그런느낌보글보글고니도새우도...\n",
      "Name: 22, dtype: object\n",
      "\n",
      "--- 다른 지역 최소 점수 문장 출력 ---\n",
      "다른 지역 데이터 최소 점수 문장:\n",
      "음식_문장     ['처음에는 그냥 조금 있어요, 나무하고 잡자재 조금이요 라고 하셨는데, 현장에 도...\n",
      "분위기_문장    ['이곳은 곧 신규 오픈을 앞두고 있는 식당으로, 사장님께서 직접 기존 인테리어를 ...\n",
      "가격_문장                                                    []\n",
      "서비스_문장    ['오늘은 충북 보은에 위치한 식당 폐기물 반출 작업을 다녀왔습니다.', '작업은 ...\n",
      "Name: 227, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 최소 점수 문장 출력\n",
    "print(\"----- 청주 최소 점수 문장 출력 -----\")\n",
    "if 'cheongju_final' in locals():\n",
    "    min_sentences = cheongju_final.loc[cheongju_final[['음식_점수', '분위기_점수', '가격_점수', '서비스_점수']].min(axis=1).idxmin()]\n",
    "    print(\"청주 데이터 최소 점수 문장:\")\n",
    "    print(min_sentences[['음식_문장', '분위기_문장', '가격_문장', '서비스_문장']])\n",
    "\n",
    "print(\"\\n--- 다른 지역 최소 점수 문장 출력 ---\")\n",
    "if 'other_final' in locals():\n",
    "    min_other_sentences = other_final.loc[other_final[['음식_점수', '분위기_점수', '가격_점수', '서비스_점수']].min(axis=1).idxmin()]\n",
    "    print(\"다른 지역 데이터 최소 점수 문장:\")\n",
    "    print(min_other_sentences[['음식_문장', '분위기_문장', '가격_문장', '서비스_문장']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "292296b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cheongju_final.to_excel(\"./crawled_data/merged_cheongju_final.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aae588d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
