{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1ea104e",
   "metadata": {},
   "source": [
    "# 전처리단계"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b72efe",
   "metadata": {},
   "source": [
    "## 중복제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b86ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "cheongju = pd.read_csv(\"./crawled_data/merged_cheongju.csv\", encoding=\"utf-8-sig\")\n",
    "other = pd.read_csv(\"./crawled_data/merged_other.csv\", encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a44862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복된 cheongju_title 데이터: 27\n",
      "중복된 other_title 데이터: 2\n"
     ]
    }
   ],
   "source": [
    "cheongju_duplicated_rows = cheongju[cheongju.duplicated(subset=['title'], keep=False)]\n",
    "print(\"중복된 cheongju_title 데이터:\", len(cheongju_duplicated_rows)) # 27\n",
    "\n",
    "other_duplicated_rows = other[other.duplicated(subset=['title'], keep=False)]\n",
    "print(\"중복된 other_title 데이터:\", len(other_duplicated_rows)) # 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448eca01",
   "metadata": {},
   "outputs": [],
   "source": [
    "cheongju = cheongju.drop_duplicates(subset=['title'], keep='first')\n",
    "other = other.drop_duplicates(subset=['title'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d895b110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복제거 후 중복된 cheongju_title 데이터: 0\n",
      "중복제거 후 중복된 other_title 데이터: 0\n"
     ]
    }
   ],
   "source": [
    "cheongju_duplicated_rows = cheongju[cheongju.duplicated(subset=['title'], keep=False)]\n",
    "print(\"중복제거 후 중복된 cheongju_title 데이터:\", len(cheongju_duplicated_rows))\n",
    "\n",
    "other_duplicated_rows = other[other.duplicated(subset=['title'], keep=False)]\n",
    "print(\"중복제거 후 중복된 other_title 데이터:\", len(other_duplicated_rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cd775f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 후 파일 저장 완료\n"
     ]
    }
   ],
   "source": [
    "#파일 덮어 씌우기\n",
    "cheongju.to_csv(\"./crawled_data/merged_cheongju.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "other.to_csv(\"./crawled_data/merged_other.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "print(\"중복 제거 후 파일 저장 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324a5ad2",
   "metadata": {},
   "source": [
    "## 익명화 및 특수문자 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "59ab6aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting emoji\n",
      "  Using cached emoji-2.14.1-py3-none-any.whl.metadata (5.7 kB)\n",
      "Using cached emoji-2.14.1-py3-none-any.whl (590 kB)\n",
      "Installing collected packages: emoji\n",
      "Successfully installed emoji-2.14.1\n"
     ]
    }
   ],
   "source": [
    "!pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8ed33b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 로딩 시작...\n",
      "'./crawled_data/merged_cheongju.csv' 파일을 'utf-8-sig'로 성공적으로 불러왔습니다.\n",
      "'./crawled_data/merged_other.csv' 파일을 'utf-8-sig'로 성공적으로 불러왔습니다.\n",
      "==================================================\n",
      "이모지 제거 작업 시작...\n",
      "'cheongju' 데이터프레임 이모지 제거 완료.\n",
      "'other' 데이터프레임 이모지 제거 완료.\n",
      "==================================================\n",
      "\n",
      "--- 청주 데이터프레임 이모지 제거 결과 (상위 5개) ---\n",
      "                                             content  \\\n",
      "0  저랑 신랑은더덕구이를 좋아하는대요신랑이 직장동료들이랑점심으로 더덕구이정식을 먹고왔는...   \n",
      "1  ​청주 가경동 냉면 식당 다녀왔어요출장을 청주로 가면 가경동에서 손님을 만나다 보니...   \n",
      "2  50m© NAVER Corp.더보기/OpenStreetMap지도 데이터x© NAVE...   \n",
      "3  청주 가경동 일식 코스 요리가족 모임하기 좋은 룸식당 어도횟집글, 사진 @네정​​​...   \n",
      "4  ​​​며칠 전 친구랑 청주 금성식당 다녀왔어요. 원래 고깃집은 워낙 자주 가는 편인...   \n",
      "\n",
      "                                     content_cleaned  \n",
      "0  저랑 신랑은더덕구이를 좋아하는대요신랑이 직장동료들이랑점심으로 더덕구이정식을 먹고왔는...  \n",
      "1  ​청주 가경동 냉면 식당 다녀왔어요출장을 청주로 가면 가경동에서 손님을 만나다 보니...  \n",
      "2  50m NAVER Corp.더보기/OpenStreetMap지도 데이터x NAVER ...  \n",
      "3  청주 가경동 일식 코스 요리가족 모임하기 좋은 룸식당 어도횟집글, 사진 @네정​​​...  \n",
      "4  ​​​며칠 전 친구랑 청주 금성식당 다녀왔어요. 원래 고깃집은 워낙 자주 가는 편인...  \n",
      "\n",
      "--- 다른 지역 데이터프레임 이모지 제거 결과 (상위 5개) ---\n",
      "                                             content  \\\n",
      "0  ​황금연어공원​​​강원도 양양 물치항 맛집물곰탕 곰치국 전문 괴산식당황금연어공원​​...   \n",
      "1  괴산도 아니면서 ㅋㅋ청주에 괴산식당은 왜 많은것이지?장소를 추가하다가 피식 웃음​청...   \n",
      "2  ​이번 여행에서 가장 많이 들린곳이 있다면바로바로 수유실 !!!휴게소에서도 ~ 쇼핑...   \n",
      "3  ​​​​​사시사철 내 속을 풀어주는 물곰탕물메기와 곰치를 지역에 따라 다르게 쓴다고...   \n",
      "4  폐업을 결정하는 순간부터 가장 먼저 떠오르는 현실적인 고민, 바로 ‘철거비’입니다....   \n",
      "\n",
      "                                     content_cleaned  \n",
      "0  ​황금연어공원​​​강원도 양양 물치항 맛집물곰탕 곰치국 전문 괴산식당황금연어공원​​...  \n",
      "1  괴산도 아니면서 ㅋㅋ청주에 괴산식당은 왜 많은것이지?장소를 추가하다가 피식 웃음​청...  \n",
      "2  ​이번 여행에서 가장 많이 들린곳이 있다면바로바로 수유실 !!!휴게소에서도 ~ 쇼핑...  \n",
      "3  ​​​​​사시사철 내 속을 풀어주는 물곰탕물메기와 곰치를 지역에 따라 다르게 쓴다고...  \n",
      "4  폐업을 결정하는 순간부터 가장 먼저 떠오르는 현실적인 고민, 바로 ‘철거비’입니다....  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import emoji\n",
    "\n",
    "# --- 데이터 안전하게 불러오기 (이전 코드 재사용) ---\n",
    "\n",
    "def load_csv_robustly(file_path):\n",
    "    \"\"\"CSV 파일을 utf-8-sig로 읽되, 실패 시 cp949로 다시 읽는 함수\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, encoding='utf-8-sig')\n",
    "        print(f\"'{file_path}' 파일을 'utf-8-sig'로 성공적으로 불러왔습니다.\")\n",
    "        return df\n",
    "    except UnicodeDecodeError:\n",
    "        print(f\"'{file_path}' 파일을 'utf-8-sig'로 읽기 실패. 'cp949'로 다시 시도합니다.\")\n",
    "        df = pd.read_csv(file_path, encoding='cp949')\n",
    "        print(f\"'{file_path}' 파일을 'cp949'로 성공적으로 불러왔습니다.\")\n",
    "        return df\n",
    "\n",
    "print(\"데이터 로딩 시작...\")\n",
    "cheongju = load_csv_robustly(\"./crawled_data/merged_cheongju.csv\")\n",
    "other = load_csv_robustly(\"./crawled_data/merged_other.csv\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# --- 이모지 제거 작업 ---\n",
    "\n",
    "# ※※※ 중요 ※※※\n",
    "# 이모지를 제거할 텍스트가 들어있는 열(column)의 이름을 정확히 지정해주세요.\n",
    "COLUMN_TO_CLEAN = 'content'\n",
    "\n",
    "# 텍스트에서 이모지를 제거하는 함수 정의\n",
    "def remove_emojis(text):\n",
    "    # emoji.replace_emoji() 함수는 텍스트 안의 모든 이모지를 찾아 replace 인자로 대체합니다.\n",
    "    # replace='' 로 지정하면 모든 이모지가 삭제됩니다.\n",
    "    return emoji.replace_emoji(str(text), replace='')\n",
    "\n",
    "print(\"이모지 제거 작업 시작...\")\n",
    "\n",
    "# cheongju 데이터프레임에 함수 적용\n",
    "if COLUMN_TO_CLEAN in cheongju.columns:\n",
    "    cheongju['content_cleaned'] = cheongju[COLUMN_TO_CLEAN].apply(remove_emojis)\n",
    "    print(\"'cheongju' 데이터프레임 이모지 제거 완료.\")\n",
    "\n",
    "# other 데이터프레임에 함수 적용\n",
    "if COLUMN_TO_CLEAN in other.columns:\n",
    "    other['content_cleaned'] = other[COLUMN_TO_CLEAN].apply(remove_emojis)\n",
    "    print(\"'other' 데이터프레임 이모지 제거 완료.\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "\n",
    "# --- 결과 확인 ---\n",
    "print(\"\\n--- 청주 데이터프레임 이모지 제거 결과 (상위 5개) ---\")\n",
    "if 'content_cleaned' in cheongju.columns:\n",
    "    # 원본과 제거 후를 비교하여 출력\n",
    "    print(cheongju[[COLUMN_TO_CLEAN, 'content_cleaned']].head())\n",
    "\n",
    "print(\"\\n--- 다른 지역 데이터프레임 이모지 제거 결과 (상위 5개) ---\")\n",
    "if 'content_cleaned' in other.columns:\n",
    "    print(other[[COLUMN_TO_CLEAN, 'content_cleaned']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7bc846",
   "metadata": {},
   "source": [
    "## 광고성 글 완전 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6340c3f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 로딩 시작...\n",
      "==================================================\n",
      "--- 광고 제거 함수 테스트 ---\n",
      "▶ 원본 텍스트:\n",
      " \n",
      "정말 맛있는 청주 맛집을 소개합니다.\n",
      "분위기도 좋고, 음식도 최고였어요.\n",
      "자세한 문의는 010-1234-5678 로 연락주세요.\n",
      "더 많은 정보는 http://myblog.com/review 에서 확인 가능합니다.\n",
      "\n",
      "#청주맛집 #분위기좋은곳\n",
      "\n",
      "<이 포스팅은 업체로부터 소정의 원고료를 지원받아 작성되었습니다.>\n",
      "\n",
      "\n",
      "▶ 제거 후 텍스트:\n",
      " 정말 맛있는 청주 맛집을 소개합니다.\n",
      "분위기도 좋고, 음식도 최고였어요.\n",
      "자세한 문의는  로 연락주세요.\n",
      "더 많은 정보는  에서 확인 가능합니다.\n",
      "\n",
      "#청주맛집 #분위기좋은곳\n",
      "==================================================\n",
      "광고성 문구 제거 작업 시작...\n",
      "'cheongju' 데이터프레임 광고 제거 완료.\n",
      "'other' 데이터프레임 광고 제거 완료.\n",
      "==================================================\n",
      "\n",
      "--- 청주 데이터프레임 광고 제거 결과 (상위 5개) ---\n",
      "                                             content  \\\n",
      "0  저랑 신랑은더덕구이를 좋아하는대요신랑이 직장동료들이랑점심으로 더덕구이정식을 먹고왔는...   \n",
      "1  ​청주 가경동 냉면 식당 다녀왔어요출장을 청주로 가면 가경동에서 손님을 만나다 보니...   \n",
      "2  50m© NAVER Corp.더보기/OpenStreetMap지도 데이터x© NAVE...   \n",
      "3  청주 가경동 일식 코스 요리가족 모임하기 좋은 룸식당 어도횟집글, 사진 @네정​​​...   \n",
      "4  ​​​며칠 전 친구랑 청주 금성식당 다녀왔어요. 원래 고깃집은 워낙 자주 가는 편인...   \n",
      "\n",
      "                                     content_cleaned  \n",
      "0  저랑 신랑은더덕구이를 좋아하는대요신랑이 직장동료들이랑점심으로 더덕구이정식을 먹고왔는...  \n",
      "1  ​청주 가경동 냉면 식당 다녀왔어요출장을 청주로 가면 가경동에서 손님을 만나다 보니...  \n",
      "2  50m© NAVER Corp.더보기/OpenStreetMap지도 데이터x© NAVE...  \n",
      "3  청주 가경동 일식 코스 요리가족 모임하기 좋은 룸식당 어도횟집글, 사진 @네정​​​...  \n",
      "4  ​​​며칠 전 친구랑 청주 금성식당 다녀왔어요. 원래 고깃집은 워낙 자주 가는 편인...  \n",
      "\n",
      "--- 다른 지역 데이터프레임 광고 제거 결과 (상위 5개) ---\n",
      "                                             content  \\\n",
      "0  ​황금연어공원​​​강원도 양양 물치항 맛집물곰탕 곰치국 전문 괴산식당황금연어공원​​...   \n",
      "1  괴산도 아니면서 ㅋㅋ청주에 괴산식당은 왜 많은것이지?장소를 추가하다가 피식 웃음​청...   \n",
      "2  ​이번 여행에서 가장 많이 들린곳이 있다면바로바로 수유실 !!!휴게소에서도 ~ 쇼핑...   \n",
      "3  ​​​​​사시사철 내 속을 풀어주는 물곰탕물메기와 곰치를 지역에 따라 다르게 쓴다고...   \n",
      "4  폐업을 결정하는 순간부터 가장 먼저 떠오르는 현실적인 고민, 바로 ‘철거비’입니다....   \n",
      "\n",
      "                                     content_cleaned  \n",
      "0  ​황금연어공원​​​강원도 양양 물치항 맛집물곰탕 곰치국 전문 괴산식당황금연어공원​​...  \n",
      "1  괴산도 아니면서 ㅋㅋ청주에 괴산식당은 왜 많은것이지?장소를 추가하다가 피식 웃음​청...  \n",
      "2  ​이번 여행에서 가장 많이 들린곳이 있다면바로바로 수유실 !!!휴게소에서도 ~ 쇼핑...  \n",
      "3  ​​​​​사시사철 내 속을 풀어주는 물곰탕물메기와 곰치를 지역에 따라 다르게 쓴다고...  \n",
      "4  폐업을 결정하는 순간부터 가장 먼저 떠오르는 현실적인 고민, 바로 ‘철거비’입니다....  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# --- 데이터 안전하게 불러오기 및 기본 전처리 (이전 코드 재사용) ---\n",
    "def load_csv_robustly(file_path):\n",
    "    \"\"\"CSV 파일을 utf-8-sig로 읽되, 실패 시 cp949로 다시 읽는 함수\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, encoding='utf-8-sig')\n",
    "        return df\n",
    "    except UnicodeDecodeError:\n",
    "        df = pd.read_csv(file_path, encoding='cp949')\n",
    "        return df\n",
    "\n",
    "print(\"데이터 로딩 시작...\")\n",
    "cheongju = load_csv_robustly(\"./crawled_data/merged_cheongju.csv\")\n",
    "other = load_csv_robustly(\"./crawled_data/merged_other.csv\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "COLUMN_TO_CLEAN = 'content' # 실제 사용하는 열 이름으로 변경하세요\n",
    "\n",
    "if COLUMN_TO_CLEAN in cheongju.columns:\n",
    "    cheongju[COLUMN_TO_CLEAN] = cheongju[COLUMN_TO_CLEAN].fillna('').astype(str)\n",
    "if COLUMN_TO_CLEAN in other.columns:\n",
    "    other[COLUMN_TO_CLEAN] = other[COLUMN_TO_CLEAN].fillna('').astype(str)\n",
    "\n",
    "\n",
    "# --- 광고성 문구 제거 작업 ---\n",
    "\n",
    "def remove_ad_text(text):\n",
    "    \"\"\"\n",
    "    텍스트에서 광고성 문구, 전화번호, URL 등을 제거하는 함수\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. 제거할 광고성 문구 리스트 (지속적으로 추가/관리 가능)\n",
    "    # 띄어쓰기가 다르거나 일부만 포함되어도 감지할 수 있도록 핵심 키워드 위주로 작성\n",
    "    ad_phrases = [\n",
    "        \"소정의 원고료\", \"소정의 수수료\", \"제품을 제공받아\", \"업체로부터\", \"지원받아 작성\",\n",
    "        \"제공받아 솔직하게\", \"솔직하게 작성한 후기\", \"체험단으로 선정\", \"체험단에 선정\",\n",
    "        \"파트너스 활동\", \"일정액의 수수료를\", \"쿠팡 파트너스\", \"내돈내산 아님\",\n",
    "        \"직접 구매하지 않은\", \"#협찬\", \"#광고\", \"#유료광고\", \"#광고포함\"\n",
    "    ]\n",
    "\n",
    "    # 텍스트를 줄 단위로 분리\n",
    "    lines = text.split('\\n')\n",
    "    clean_lines = []\n",
    "\n",
    "    for line in lines:\n",
    "        is_ad_line = False\n",
    "        # 광고 문구 리스트에 있는 단어가 포함된 줄인지 확인\n",
    "        for phrase in ad_phrases:\n",
    "            if phrase in line:\n",
    "                is_ad_line = True\n",
    "                break\n",
    "        \n",
    "        # 광고 문구가 포함되지 않은 줄만 clean_lines에 추가\n",
    "        if not is_ad_line:\n",
    "            clean_lines.append(line)\n",
    "            \n",
    "    # 깨끗해진 줄들을 다시 하나의 텍스트로 합침\n",
    "    text = '\\n'.join(clean_lines)\n",
    "\n",
    "    # 2. 정규표현식을 사용하여 전화번호 제거 (e.g., 010-1234-5678, 043-123-4567)\n",
    "    phone_pattern = re.compile(r'\\d{2,3}-\\d{3,4}-\\d{4}')\n",
    "    text = phone_pattern.sub('', text)\n",
    "\n",
    "    # 3. 정규표현식을 사용하여 URL 제거\n",
    "    url_pattern = re.compile(r'https?:\\/\\/(?:www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b(?:[-a-zA-Z0-9()@:%_\\+.~#?&//=]*)')\n",
    "    text = url_pattern.sub('', text)\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "# --- 테스트를 위한 예제 텍스트 ---\n",
    "sample_text = \"\"\"\n",
    "정말 맛있는 청주 맛집을 소개합니다.\n",
    "분위기도 좋고, 음식도 최고였어요.\n",
    "자세한 문의는 010-1234-5678 로 연락주세요.\n",
    "더 많은 정보는 http://myblog.com/review 에서 확인 가능합니다.\n",
    "\n",
    "#청주맛집 #분위기좋은곳\n",
    "\n",
    "<이 포스팅은 업체로부터 소정의 원고료를 지원받아 작성되었습니다.>\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- 광고 제거 함수 테스트 ---\")\n",
    "cleaned_sample = remove_ad_text(sample_text)\n",
    "print(\"▶ 원본 텍스트:\\n\", sample_text)\n",
    "print(\"\\n▶ 제거 후 텍스트:\\n\", cleaned_sample)\n",
    "print(\"=\"*50)\n",
    "\n",
    "\n",
    "# --- 실제 데이터프레임에 함수 적용 ---\n",
    "\n",
    "print(\"광고성 문구 제거 작업 시작...\")\n",
    "\n",
    "# cheongju 데이터프레임에 함수 적용\n",
    "if COLUMN_TO_CLEAN in cheongju.columns:\n",
    "    # 'content_cleaned' 열이 이미 있다면 그 위에 덮어쓰고, 없다면 새로 생성\n",
    "    cheongju['content_cleaned'] = cheongju[COLUMN_TO_CLEAN].apply(remove_ad_text)\n",
    "    print(\"'cheongju' 데이터프레임 광고 제거 완료.\")\n",
    "\n",
    "# other 데이터프레임에 함수 적용\n",
    "if COLUMN_TO_CLEAN in other.columns:\n",
    "    other['content_cleaned'] = other[COLUMN_TO_CLEAN].apply(remove_ad_text)\n",
    "    print(\"'other' 데이터프레임 광고 제거 완료.\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# --- 결과 확인 ---\n",
    "print(\"\\n--- 청주 데이터프레임 광고 제거 결과 (상위 5개) ---\")\n",
    "if 'content_cleaned' in cheongju.columns:\n",
    "    print(cheongju[[COLUMN_TO_CLEAN, 'content_cleaned']].head())\n",
    "print(\"\\n--- 다른 지역 데이터프레임 광고 제거 결과 (상위 5개) ---\")\n",
    "if 'content_cleaned' in other.columns:\n",
    "    print(other[[COLUMN_TO_CLEAN, 'content_cleaned']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e084d2",
   "metadata": {},
   "source": [
    "## 데이터 기간 동일화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6fb582e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 로딩 시작...\n",
      "==================================================\n",
      "필터링 전 'other' 데이터프레임의 정보:\n",
      " - 전체 행 개수: 896\n",
      " - 가장 오래된 날짜: 20060824\n",
      "==================================================\n",
      "'date' 열을 날짜(datetime) 형식으로 성공적으로 변환했습니다.\n",
      "\n",
      "기준 날짜 (cheongju의 최소 날짜): 2013-11-18\n",
      "\n",
      "필터링 후 'other' 데이터프레임의 정보:\n",
      " - 전체 행 개수: 892\n",
      " - 가장 오래된 날짜: 2013-11-27\n",
      "-> 4개의 오래된 데이터가 삭제되었습니다.\n",
      "==================================================\n",
      "'other' 데이터프레임이 성공적으로 필터링되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --- 데이터 안전하게 불러오기 (이전 코드 재사용) ---\n",
    "def load_csv_robustly(file_path):\n",
    "    \"\"\"CSV 파일을 utf-8-sig로 읽되, 실패 시 cp949로 다시 읽는 함수\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, encoding='utf-8-sig')\n",
    "        return df\n",
    "    except UnicodeDecodeError:\n",
    "        df = pd.read_csv(file_path, encoding='cp949')\n",
    "        return df\n",
    "\n",
    "print(\"데이터 로딩 시작...\")\n",
    "cheongju = load_csv_robustly(\"./crawled_data/merged_cheongju.csv\")\n",
    "other = load_csv_robustly(\"./crawled_data/merged_other.csv\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# --- 날짜 기준으로 데이터 필터링 ---\n",
    "\n",
    "# ※※※ 중요 ※※※\n",
    "# 날짜가 들어있는 열(column)의 이름을 정확히 지정해주세요.\n",
    "DATE_COLUMN = 'date'\n",
    "\n",
    "print(f\"필터링 전 'other' 데이터프레임의 정보:\")\n",
    "print(f\" - 전체 행 개수: {len(other)}\")\n",
    "print(f\" - 가장 오래된 날짜: {other[DATE_COLUMN].min()}\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# 1. 'date' 열을 날짜(datetime) 형식으로 변환\n",
    "#    - to_datetime 함수가 YYYYMMDD 형식의 숫자를 날짜로 똑똑하게 변환해 줍니다.\n",
    "#    - errors='coerce' 옵션은 만약 날짜 형식이 아닌 값이 있을 경우, 해당 값을 NaT(Not a Time)으로 만들어 오류를 방지합니다.\n",
    "try:\n",
    "    cheongju[DATE_COLUMN] = pd.to_datetime(cheongju[DATE_COLUMN], format='%Y%m%d', errors='coerce')\n",
    "    other[DATE_COLUMN] = pd.to_datetime(other[DATE_COLUMN], format='%Y%m%d', errors='coerce')\n",
    "    print(\"'date' 열을 날짜(datetime) 형식으로 성공적으로 변환했습니다.\")\n",
    "except Exception as e:\n",
    "    print(f\"'date' 열 변환 중 오류 발생: {e}. 데이터 타입을 확인해주세요.\")\n",
    "\n",
    "\n",
    "# 2. cheongju 데이터프레임에서 기준이 될 최소 날짜(가장 오래된 날짜)를 찾기\n",
    "min_date_standard = cheongju[DATE_COLUMN].min()\n",
    "print(f\"\\n기준 날짜 (cheongju의 최소 날짜): {min_date_standard.strftime('%Y-%m-%d')}\")\n",
    "\n",
    "\n",
    "# 3. other 데이터프레임에서 기준 날짜보다 오래된 데이터를 삭제\n",
    "#    - other 데이터프레임의 'date'가 기준 날짜보다 크거나 같은 행만 남깁니다.\n",
    "other_filtered = other[other[DATE_COLUMN] >= min_date_standard].copy()\n",
    "\n",
    "\n",
    "# 4. 결과 확인\n",
    "print(\"\\n필터링 후 'other' 데이터프레임의 정보:\")\n",
    "print(f\" - 전체 행 개수: {len(other_filtered)}\")\n",
    "print(f\" - 가장 오래된 날짜: {other_filtered[DATE_COLUMN].min().strftime('%Y-%m-%d')}\")\n",
    "print(f\"-> {len(other) - len(other_filtered)}개의 오래된 데이터가 삭제되었습니다.\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# 5. 원래의 other 변수에 필터링된 결과 덮어쓰기\n",
    "other = other_filtered\n",
    "\n",
    "# 이제 'other' 데이터프레임은 cheongju와 동일한 날짜 기준을 가지게 되었습니다.\n",
    "print(\"'other' 데이터프레임이 성공적으로 필터링되었습니다.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
